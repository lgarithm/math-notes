% !TEX program = pdflatex

\documentclass{article}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{enumerate}
\usepackage{color}
\usepackage[
  colorlinks,
  citecolor=black,
  filecolor=black,
  linkcolor=black,
  urlcolor=black
  colorlinks=true,
  linktoc=all,
  linkcolor=blue,
  linktocpage=true
]{hyperref}

\newtheorem*{pro}{Proposition}
\newtheorem*{thm}{Theorem}
\def\ch{\mathop{\mathrm{char}}}
\def\hom{\mathop{\mathrm{Hom}}}
\def\rank{\mathop{\mathrm{rank}}}

\title{Notes for Algebra}
\author{Lgarithm\\\mbox{lgarithm@gmail.com}}

\begin{document}
\maketitle
\newpage
\tableofcontents
\newpage


\section{Formal Definition}
Let $R$ be a commutative ring with identity.

\subsection{Formal Power Series}
A formal power series $a$ over $R$ is a map $a : \mathbb N \to R$,
written as $$\sum a_n X^n$$

The set of all formal power series over $R$ is denoted by $R[[X]]$,
it is the free algebra over $R$ generated by a transcendent element $X$.

When $R$ is a domain, $R[[X]]$ is also a domain.

Two simple but important examples are
\begin{align*}
  {1 \over 1 - X} &= 1 + X + X^2 + \cdots + X^n + \cdots \\
  {1 \over (1 - X)^{1 + k}} &= \sum_{n = 0}^\infty {n + k \choose k} X^n
\end{align*}
The second identity can be obtained by taking the $(k + 1)$-th power of the first one on both sides.

For a field $K$, $K[[X]]$ is a local ring with the unique maximal ideal $(X)$.
Which means a formal power series has inverse when and only when it has non-zero constant term.
In concrete terms, the inverse of formal power series
$$1 + a_1 X + \cdots + a_n X^n + \cdots$$
can be calculated in a ring. Assume
$$1 = (1 + a_1 X + \cdots + a_n X^n + \cdots) (1 + b_1 X + \cdots + b_n X^n + \cdots)$$
then we have the following relations
\begin{align*}
    a_1 + b_1 = 0 \\
    a_2 + a_1b_1 + b_2 = 0 \\
    \vdots \\
    a_n + a_{n-1}b_1 + \cdots + a_1b_{n-1} + b_n = 0 \\
    \vdots
\end{align*}
each $b_i$ can be uniquely determined starts from $b_1$. In fact,
$$b_n = \sum_{i_1 + \cdots + i_k = n} (-1)^k a_{i_1} \cdots a_{i_k}$$

\subsection{Semigroup Algebra}
Let $M$ be a semi-group, $R$ a ring, and $f : M \to R$ a map from $M$ to $R$.
We call the value of $f$ at $m$ the coefficient of term $x^m$ and write it as $f_m$ instead of $f(m)$.
The function $f$ is determined by its values at all points in $M$, therefore $f$ can be written
formally as $$f = \sum f_m x^m$$

Let $$R[[M]] = \{f \mid f : M \to R\}$$ and $R[M] \subseteq R[[M]]$ be the subset
of the maps $f : M \to R$ which only have finite many non-zero coefficients.
When $M$ is finite, they are identical.
Note that $R[[M]]$ is the free $R$-module with basis $M$.

Define a binary operation on $R[M]$, called convolution, by
$$fg = \sum (\sum_{hk = m} f_h g_k) x^m$$
This operation is well defined because the coefficient of $x^m$ in the production $\sum_{hk=m} f_k g_k$
is the sum of only finite many terms. It's easy to check that this operation is associative and $R$-bilinear.
Therefore $R[M]$ forms an $R$-algebra.

For example, take $M = (\mathbb N, +)$, the semi-group of natural numbers with addition operation,
then $R[M]$ is just the algebra of polynomials of one variable over $R$, usually denoted by $R[X]$.

For some semi-group $M$, the convolution is also well defined on $R[[M]]$,
when the set $\{(h, k) \mid hk = m\}$ is finite for all $m \in M$.

This condition holds for $M = (\mathbb N, +)$, where $R[[M]]$ is just the formal power series of one variable.

When $M = (\mathbb N, \ast)$, $R[[M]]$ becomes the algrbra of arithmetic functions,
and the product is the Dirichlet convolution.

\subsection{Semigroupoid Algebra}
But the incidence algebra can not be defined in this way, which needs further genralization.
Recall the definition of incidence algebra:
Let $P$ be a poset, $Q = \{(g, h) \mid g \leq h\} \subset P \times P$,
$\alpha, \beta : Q \to R$,
$$\alpha\beta = \sum (\sum_{g\leq k \leq h} \alpha_{g,k} \beta_{k,h})x^{g,h}$$
We can define an associative partial binary operation $\circ$ on $Q$,
$$\circ : Q \times Q \to Q$$
$$(x, y) \circ (y, z) \to (x, z)$$
but it doesn't make $Q$ into a semi-group.
This kind of algebra strutcutr is called a semi-groupoid.
Howevery a semi-group is the special case of a semi-groupoid,
therefore we may generatlize the definition of semi-group algebra
to semi-groupoid algebra and still use $R[Q]$ for the incidence algebra of $P$.
For $f : P \to R$, we have another kind of product
$$(\alpha f) = \sum (\sum_{g\leq h} \alpha_{g, h} f_h)x^g$$
$$(f \alpha) = \sum (\sum_{h\leq g} f_h \alpha_{h, g})x^g$$

\subsection{Polynomial of Several Variables}
A polynomial of $n$ variables over $R$ is a map from
$\mathbb N^n$ to $R$ such that the support set is finite.
Let $X_1, \dots, X_n$ be $n$ non-determinants,
the value of the map at $(i_1, \dots, i_n)$
is called the coefficient of $X_1^{i_1}\cdots X_n^{i_n}$,
if denoted by $a_{i_1\dots i_n}$, then $f$ itself is denoted by
$$f(X_1, \dots, X_n) = \sum a_{i_1\dots i_n} X_1^{i_1}\cdots X_n^{i_n}$$
To simplify the notation, we can write
$$f(X) = \sum a_I X^I\mbox{ or just } f = \sum a_I X^I$$
where $I = (i_1, \dots, i_n)$ is called a multiple index,
$X = (X_1, \dots, X_n)$ is called a multiple variable,
and $X^I$ actually means $X_1^{i_1}\cdots X_n^{i_n}$.

Since the support of the map if finite, there are only finite terms
in the summation. The degree of $f$, $\deg f$ is define as $\max \{\sum i_j\}$.

 The set of all polynomials of $n$ variables $X_1, \dots, X_n$
over $R$ is denoted by $R[X_1, \dots, X_n]$.

\subsection{Polynomial Map}
Since we can take values in to a polynomial by replacing
the $n$ non-determinants to $n$ elements of $R$,
each polynomial induce a function $f^\flat : R^n \to R$ in this way.

That is, if
$$f(X_1, \dots, X_n) = \sum a_{i_1\dots i_n} X_1^{i_1}\cdots X_n^{i_n}$$
then $f^\flat : R^n \to R$ is definted by
$$f^\flat(x_1, \dots, x_n) = \sum a_{i_1\dots i_n} x_1^{i_1}\cdots x_n^{i_n}$$
where $x_i \in R$.

For a function $h : R^n \to R$, if there exists a polynomial $f$ such
that $f^\flat = h$, we then call $h$ a polynomial map on $R^n$,
and use $h^\sharp$ to denote the coressponding polynomial.

\subsection{Valuation Map}
For a point $x = (x_1, \dots, x_n)$ of $R^n$, we can define a map
$$e_x : R[X_1, \dots, X_n] \to R$$ by letting
$$e_x(f) = f^\flat(x)$$
this is called a valuation map.

The valuation $e_x$ map is an $R$-linear map from $R[X_1, \dots, X_n]$ to $R$, that is,
$$e_x(f + g) = e_x(f) + e_x(g)$$
$$e_x(af) = a e_x(f)$$
besides
$$e_x(fg) = e_x(f) e_x(g)$$


\section{Algebra of Polynomials}
\subsection{Addition and Multiplication}
Let $f = \sum a_I X^I$ and $g = \sum b_I X^I$ be two polynomials,
define $$f + g = \sum (a_I + b_I) X^I$$
and $$fg = \sum a_I b_J X^{I+J}= \sum (\sum_{I + J = K} a_I b_J) X^K.$$
Then $R[X_1, \dots, X_n]$ is made into a commutative ring.

If we consider the set of all possible multiple indexes $\mathbb N^n$,
which is actually a semi-group under the point-wise sum operation.
Then the ring $R[X_1, \dots, X_n]$ is exactly the semi-group ring $R[\mathbb N^n]$.

The map $i : R \to R[X_1, \dots, X_n]$ which takes an element of $R$ to a constant polynomial
in $R[X_1, \dots, X_n]$ is a well defined homomorphism of rings,
therefore $R[X_1, \dots, X_n]$ is a well defined $R$-algebra.
In fact, it is exactly the free algrbra over $R$, which means extend $R$ by adding $n$ algebraically
independent elements.

The evaluation map $e_x : R[X_1, \dots, X_n] \to R$ is a ring homomosphism from earlier observation.

If we define $X_i$ and $X_j$ to be non-commutative, then $R[X_1, \dots, X_n]$ becomes the
semi-group ring $R[M]$ where $M$ is the free monoid of rank $n$.

\subsection{Ideal}
A ring is called a noetherian ring if all its ideals are finite generated.
Especially a PID is a noetherian ring.
The Hilbert's basis theorem says if $R$ is a noetherian ring, so is $R[X]$,
therefore $R[X_1, \dots, X_n]$ is a noetherian ring by induction.

% \subsection{Lift}
% Let $V$ be subset of $R^n$,
% a function $h : V \to R$ is a polynomial map if $h = f^\flat \vert_V$ for some $f$.
% If we use $h^\sharp$ to denoted all such $f$, $h^\sharp$ will be an ideal of $R[X_1, \dots, X_n]$.

\subsection{Homomorphism}
In this subsection, we will describe some traditional concepts of polynomial in terms of homomorphism
of $R$-algebra.

Let $A$ be any $R$-algebra, $$\varphi : R[X_1, \dots, X_n] \to A$$ a homomorphism of $R$-algebra,
then $\varphi$ is uniquely determined by a permutation of $n$ elements $a_i = \varphi(X_i) \in A$,
$i = 1, \dots n$.

For $f \in R[X_1, \dots, X_n]$, $\varphi(f)$ is exactly $f^\flat(\varphi(X_1), \dots, \varphi(X_n))$
in traditonal notation. That is, $\varphi = e_a$, where $a = (\varphi(X_1), \dots, \varphi(X_n)) \in A^n$.

If $\varphi(f) = 0$, then $a = (a_1, \dots, a_n)$ is call a zero of $F$ in $A^n$.
Since $a$ gives the homomorphism $\varphi$, we can also say $\varphi$ is the zero of $f$.

In elementary algebra, we may take values into the variables of a polynomial, and got a new polynomial
with less variables, or even a pure value in the ring $R$. Or we may replace each variable of $f$ by
polynomials. Now we can give more rigorous description in terms of homomorphism.

When $A = R$, let $(\varphi_1, \dots, \varphi_n) = (a_1, \dots, a_n) = a \in R^n$,
we got the evaluation of $f$ at $a$.

When $A = R[Y_1, \dots, Y_m]$, $\varphi_i = \varphi_i(Y_1, \dots, Y_m)$,
then $\varphi(f) = g(Y_1, \dots, Y_m)$, $\varphi$ is just a change of variables
$(X_1, \dots, X_n)$ to $(Y_1, \dots, Y_m)$ in traditional sense.


\subsection{Form}
A form is a homogenious polynomial, which means each term has the same total degree.
The set of all $m$-degree forms $R^m[X_1, \dots, X_n]$ is a submodule of $R[X_1, \dots, X_n]$,

The forms of $0$-degree are just $R$ and the linear forms are just $R^n$,
the free $R$-module of rank $n$, generated by $X_1, \dots, X_n$.
For $m > 1$, $\rank R^m[X_1, \dots, X_n] = {n + m - 1\choose n - 1}$.

$$R^0[X_1, \dots, X_n] \cong R$$
$$R^1[X_1, \dots, X_n] \cong R^n$$
$$R^k[X_1, \dots, X_n] \times R^m[X_1, \dots, X_n] \to R^{k+m}[X_1, \dots, X_n]$$

$R[X_1, \dots, X_n]$ is a graded ring with decomposition:
$R[X_1, \dots, X_n] \cong R^0[X_1, \dots, X_n] \oplus R^1[X_1, \dots, X_n] \oplus
\cdots \oplus R^m[X_1, \dots, X_n] \oplus \cdots$.
For $f \in R[X_1, \dots, X_n]$, there is a unique way to write
$f = f_0 + f_1 + \cdots + f_m$ where $f_k$ are forms with different degree.

There is a one to one coresspondence between $R^m[X_1, \dots, X_{n+1}]$ and the set of
polynomials with degree at most $m$ in $R[X_1, \dots, X_n]$.
\begin{align*}
X_1^{e_1}\cdots X_n^{e_n} &\to X_1^{e_1}\cdots X_n^{e_n} X_{n+1}^{m - (e_1 + \cdots + e_n)} \\
X_1^{e_1}\cdots X_n^{e_n} X_{n+1}^{e_{n+1}} &\to X_1^{e_1}\cdots X_n^{e_n}
\end{align*}

The second one is a homomorphism ${ }_\ast \to R[X_1, \dots, X_{n+1}] \to R[X_1, \dots, X_n]$
\begin{align*}
X_i &\to X_i \quad (1 \leq i \leq n)\\
X_{n + 1} &\to 1
\end{align*}
The first can be considered as
$f(X_1, \dots, X_n) \to X_{n+1}^m f(X_1 / X_{n+1}, \dots, X_n / X_{n+1})$,
but this will introduces the rational function field $R(X_1, \dots, X_{n+1})$.

% For $n > 0$, $\sum_{k=0}^m {k + n - 1 \choose n - 1} = {m + n \choose n}$

\subsection{Symmetric Polynominals}
Let $X_1, X_2, \dots, X_n$ be non-determined elements,
define the symmetric polynomial $\sigma_k(X_1, \dots, X_n)$
to be the sum of all possible products of choosing $k$ from $X_1, \dots, X_n$,
in concrete terms:
\begin{align*}
  &\sigma_k(X_1, \dots, X_n) \\
  = &\sum X_{i_1} \cdots X_{i_k} \\
  = &\sum \prod_{j=1}^{k} X_{i_j}
\end{align*}
where $\{i_1, \dots, i_k\}$ run through all possible $k$-combinations of $\{1, \dots n\}$.

$\sigma_k(X_1, \dots, X_n) = 1$ when $k = 0$ and $\sigma_k(X_1, \dots, X_n) = 0$ when $k > n$.

Let $Y$ be another non-determined element, we have
$$\prod_{i=1}^{n} (Y + X_i) = \sum_{k=0}^{n} \sigma_k(X_1, \dots, X_n) Y^{n - k}$$
\begin{align*}
  (Y + X_1) \cdots (Y + X_n)
  &= Y^n + (X_1 + \cdots + X_n) Y^{n - 1} + \cdots + X_1 \cdots  X_n \\
  &= Y^n + \sigma_1(X_1, \dots, X_n) Y^{n - 1} + \cdots + \sigma_n(X_1, \dots, X_n)
\end{align*}
\begin{pro}
Let $\pi \in S_n$ be a permutation of $n$ elements, then $\forall k$
$$\sigma_k(X_1, X_2, \dots, X_n) = \sigma_k(X_{\pi(1)}, X_{\pi(2)}, \dots, X_{\pi(n)})$$
\end{pro}
Let $X = (X_1, \dots, X_n)$, define $\pi(X) = (X_{\pi(1)}, \dots, X_{\pi(n)})$,
this proposition can be state as $\sigma_k(\pi(X)) = \sigma_k(X)$ for all $\pi \in S_n$.
A polynomial who has this property is called a symmetric polynomial,
$\sigma_k$ are called elementary symmetric polynomials.
\begin{thm}
Every symmetric polynomial of $X_1, \dots, X_n$ can be represent by a polynomial of
$\sigma_1, \dots, \sigma_n$.
\end{thm}

In other words, this theorem says, if
\begin{align*}
  \sigma: K[\sigma_1, \dots, \sigma_n] &\to K[X_1, \dots, X_n] \\
  \sigma_1 &\to X_1 + \cdots + X_n \\
  &\vdots \\
  \sigma_n &\to X_1 \cdots X_n
\end{align*}
is a homorphism of polynomials rings, the image of $\sigma$ is
exactly the symmetric polynomials.

\subsection{Sum of Powers}
Let $S_0 = n$ and $S_k = X_1^k + \cdots + X_n^k$ when $k > 0$.
$S_k$ are symmetric polynomials of $X_1, \dots, X_n$.
In particular case, when $X_i = i$, $S_k = 1^k + \cdots + n^k$ is the sum of $k$-th power
of the first $n$ positive integers.

\begin{align*}
    1 + 2 + \cdots + n &= {n(n + 1) \over 2} \\
    1^2 + 2^2 + \cdots + n^2 &= {n(n + 1)(2n + 1) \over 6} \\
    1^3 + 2^3 + \cdots + n^3 &= {n^2(n + 1)^2 \over 4}
\end{align*}
In general, $S_k(n)$ is a $(k + 1)$-th polynomial of $n$.


\section{Derivative}
For polynomials, the derivative can be defined without limit.

\subsection{Partial Derivative}
For $f(X_1, \dots, X_n) \in R[X_1, \dots, X_n]$, we define $n$ linear operators
$$\partial_i = {\partial \over \partial X_i} : R[X_1, \dots, X_n] \to R[X_1, \dots, X_n]$$
$$\partial_i(X_1^{e_1} \cdots X_n^{e_n}) = e_i X_1^{e_1} \cdots X_i^{e_i-1} \cdots X_n^{e_n}$$

Observe that $\partial_i(\partial_j(f)) = \partial_j(\partial_i(f))$, we may define
a graded ring $R[\partial_1, \dots, \partial_n]$, which is the free commutative algebra generated by
$\partial_i$.

For $d \in R^k[\partial_1, \dots, \partial_n]$ and $f \in R^m[X_1, \dots, X_n]$,
$$d(f) \in R^{m-k}[X_1, \dots, X_n]$$
when $k > m$, $d(f) = 0$.

For linear derivative operators, we have
\begin{thm}
For $d \in R^1[\partial_1, \dots, \partial_n]$,
\begin{enumerate}
\item $d(fg) = d(f)g + fd(g)$
\item $d^n(fg) = \sum^n_{k=0} {n \choose k}d^{n-k}(f) d^k(g)$
\end{enumerate}
\end{thm}

\begin{thm}
For a homomorphism $\varphi : R[X_1, \dots, X_n] \to R[Y_1, \dots, Y_m]$
and $d \in R^1[\partial_1, \dots, \partial_m]$,
$$d(\varphi(f)) = \sum_{k=1}^n \varphi(\partial_k(f)) d(\varphi(X_k))$$
\end{thm}

If we extend the coefficient ring of derivative operators to $R[X_1, \dots, X_n]$,
then our ring of derivative operators becomes $R[X_1, \dots, X_n, \partial_1, \dots, \partial_n]$.
However we should be very careful that $x_i$ and $\partial_i$ is not commutative.
In fact they satisifies the relation $\partial_i X_i - X_i \partial_i = 1$.
Here $\partial_i X_i$ means multiply by $X_i$ first, then take partial derivative at $X_i$.
It is known as the Weyl algebra.

\begin{thm}[Euler]
$$(\sum X_k \partial_k)(f) = \deg f$$
\end{thm}

\section{Field of Rational Functions}
In this section we assume $R$ is a domain, so is $R[X_1, \dots, X_n]$.

The field of fractions of $R[X_1, \dots, X_n]$ is call the field of rational functions,
denoted by $R(X_1, \dots, X_n)$. Each element of $R(X_1, \dots, X_n)$ will be called an
rational function.

Let $A$ be an $R$-algebra, for $f \in R[X_1, \dots, X_n]$, we have a well defined function
$f^\flat : A^n \to A$, given by $a \to e_a(f)$, where $a = (a_1, \dots, a_n) \in A^n$
and $e_a$ is the $R$-algebra homomorphism $R[X_1, \dots, X_n] \to A$ that sends $X_i$ to $a_i$.

Howevery, for $r = {f \over g} \in R(X_1, \dots, X_n)$ where $(f, g) = 1$, the rational map
$r^\flat : A^n \to A$ given by $r^\flat(a) = f^\flat(a) / g^\flat(a)$
may not well defined, for $g^\flat(a) = 0$ may happen for sime $a \in A^n$.
In this case it's we may consider a subset $U$ of $A^n$ on which $r^\flat$ is well defined,
i.e. $U \subseteq A^n \backslash Z(g)$.

\subsection{Derivative of Rational Functions}
The relation $$d(f/g) = {fd(g) - d(f)g \over f^2}$$ holds for linear derivative operator $d$.

\section{Invariant}
\subsection{Change of Variables}
We now consider the group $GL(n, R)$ acts on $R[X_1, \dots, X_n]$.
Let $T \in GL(n, R)$,
\begin{equation*}
  T = \left(\begin{matrix}
    t_{11} & \cdots & t_{1n} \cr
    \vdots & \ddots & \vdots \cr
    t_{n1} & \cdots & t_{nn}
\end{matrix}\right)
\end{equation*}
and $f = \sum a_I X^I$, then $f^\flat \circ T : R^n \to R$ is
obviously a polynomial map on $R^n$, the action is given by
$T : f \to (f^\flat \circ T)^\sharp$.


\subsection{Definition of Invariant}
An invariant $I$ of $f$ with respect to $T$ is a function of $f$,
such that $I(f) = (\det T)^\omega I(T(f))$, when $\omega = 0$,
$I$ is called an absolute invariant.


\section{Variety}
\subsection{Affine Variety}
Let $k$ be a field, for any $k$-algebra $K$, the affine space of dimension $n$,
denoted by $\mathbb A^n(K)$, is just the $n$-fold Cartesian product of $K$
$$\mathbb A^n(K) = \{(a_1, \dots, a_n) \mid a_i \in K\} = K^n$$
For a set of polynomials $S \subseteq k[x_1, \dots, x_n]$,
the set of their common zeros in $\mathbb A^n(K)$ is called an algebraic set,
which is a subset of $\mathbb A^n(K)$.

Let $U$ be an algebraic set, $P(U, K) = \{ f^\flat\vert_U \mid f \in k[x_1, \dots, x_n] \}$,
the set of polynomial maps on $U$ forms a $k$-algebra $\Gamma(U)$, usually called the coordinate ring,
is isomorphism to $k[x_1, \dots, x_n]/I(U)$.

Let $\mathcal C$ be the category of coordinate rings, and $\mathcal V$ be the category of algebraic sets,
then $\Gamma$ can be viewed as a covariant functor from $\mathcal V$ to $\mathcal C$, where the morphism of
arrows is given by $\tau$

$$\tau : \hom(U, V) \to \hom(\Gamma(V), \Gamma(U))$$
$$\tau(\varphi) : g \to g \circ \varphi$$

$$\pi : \hom(\Gamma(V), \Gamma(U)) \to \hom(U, V)$$
$$\pi(\sigma) : x \to (\sigma(y_1)(x), \dots, \sigma(y_m)(x))$$

\end{document}
